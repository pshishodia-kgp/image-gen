{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/workspace/image-gen/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from flux.pipeline import FluxSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading T5 took 4.71s\n",
      "Loading CLIP took 0.31s\n",
      "Init model\n",
      "Loading checkpoint\n",
      "Loading flow model took 3.59s\n",
      "Init AE\n",
      "Loading autoencoder took 0.14s\n"
     ]
    }
   ],
   "source": [
    "flux_sampler = FluxSampler(name = 'flux-dev', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# flux_sampler.model = torch.compile(flux_sampler.model)\n",
    "# flux_sampler.t5 = torch.compile(flux_sampler.t5)\n",
    "# flux_sampler.clip = torch.compile(flux_sampler.clip)\n",
    "# flux_sampler.ae = torch.compile(flux_sampler.ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: img_in.weight, dtype: torch.bfloat16\n",
      "Tensor: img_in.bias, dtype: torch.bfloat16\n",
      "Tensor: time_in.in_layer.weight, dtype: torch.bfloat16\n",
      "Tensor: time_in.in_layer.bias, dtype: torch.bfloat16\n",
      "Tensor: time_in.out_layer.weight, dtype: torch.bfloat16\n",
      "Tensor: time_in.out_layer.bias, dtype: torch.bfloat16\n",
      "Tensor: vector_in.in_layer.weight, dtype: torch.bfloat16\n",
      "Tensor: vector_in.in_layer.bias, dtype: torch.bfloat16\n",
      "Tensor: vector_in.out_layer.weight, dtype: torch.bfloat16\n",
      "Tensor: vector_in.out_layer.bias, dtype: torch.bfloat16\n",
      "Tensor: guidance_in.in_layer.weight, dtype: torch.bfloat16\n",
      "Tensor: guidance_in.in_layer.bias, dtype: torch.bfloat16\n",
      "Tensor: guidance_in.out_layer.weight, dtype: torch.bfloat16\n",
      "Tensor: guidance_in.out_layer.bias, dtype: torch.bfloat16\n",
      "Tensor: txt_in.weight, dtype: torch.bfloat16\n",
      "Tensor: txt_in.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.0.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.1.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.2.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.3.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.4.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.5.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.6.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.7.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.8.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.9.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.10.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.11.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.12.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.13.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.14.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.15.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.16.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.17.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.img_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.img_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.img_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.img_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.img_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.img_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.img_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.img_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.img_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.img_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.txt_mod.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.txt_mod.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.txt_attn.qkv.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.txt_attn.qkv.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.txt_attn.proj.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.txt_attn.proj.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.txt_mlp.0.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.txt_mlp.0.bias, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.txt_mlp.2.weight, dtype: torch.bfloat16\n",
      "Tensor: double_blocks.18.txt_mlp.2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.0.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.0.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.0.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.0.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.0.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.0.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.1.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.1.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.1.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.1.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.1.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.1.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.2.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.2.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.2.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.2.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.2.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.2.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.3.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.3.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.3.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.3.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.3.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.3.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.4.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.4.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.4.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.4.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.4.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.4.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.5.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.5.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.5.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.5.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.5.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.5.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.6.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.6.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.6.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.6.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.6.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.6.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.7.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.7.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.7.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.7.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.7.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.7.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.8.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.8.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.8.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.8.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.8.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.8.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.9.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.9.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.9.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.9.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.9.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.9.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.10.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.10.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.10.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.10.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.10.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.10.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.11.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.11.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.11.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.11.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.11.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.11.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.12.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.12.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.12.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.12.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.12.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.12.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.13.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.13.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.13.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.13.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.13.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.13.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.14.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.14.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.14.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.14.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.14.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.14.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.15.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.15.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.15.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.15.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.15.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.15.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.16.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.16.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.16.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.16.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.16.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.16.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.17.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.17.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.17.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.17.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.17.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.17.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.18.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.18.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.18.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.18.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.18.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.18.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.19.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.19.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.19.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.19.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.19.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.19.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.20.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.20.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.20.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.20.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.20.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.20.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.21.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.21.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.21.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.21.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.21.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.21.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.22.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.22.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.22.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.22.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.22.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.22.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.23.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.23.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.23.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.23.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.23.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.23.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.24.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.24.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.24.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.24.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.24.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.24.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.25.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.25.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.25.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.25.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.25.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.25.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.26.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.26.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.26.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.26.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.26.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.26.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.27.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.27.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.27.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.27.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.27.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.27.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.28.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.28.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.28.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.28.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.28.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.28.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.29.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.29.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.29.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.29.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.29.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.29.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.30.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.30.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.30.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.30.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.30.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.30.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.31.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.31.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.31.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.31.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.31.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.31.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.32.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.32.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.32.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.32.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.32.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.32.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.33.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.33.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.33.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.33.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.33.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.33.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.34.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.34.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.34.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.34.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.34.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.34.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.35.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.35.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.35.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.35.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.35.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.35.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.36.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.36.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.36.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.36.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.36.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.36.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.37.linear1.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.37.linear1.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.37.linear2.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.37.linear2.bias, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.37.modulation.lin.weight, dtype: torch.bfloat16\n",
      "Tensor: single_blocks.37.modulation.lin.bias, dtype: torch.bfloat16\n",
      "Tensor: final_layer.linear.weight, dtype: torch.bfloat16\n",
      "Tensor: final_layer.linear.bias, dtype: torch.bfloat16\n",
      "Tensor: final_layer.adaLN_modulation.1.weight, dtype: torch.bfloat16\n",
      "Tensor: final_layer.adaLN_modulation.1.bias, dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "for name, tensor in flux_sampler.model.named_modules():\n",
    "    if hasattr(tensor, \"weight\"): # check if it's a layer, linear or conv, etc.\n",
    "       for n, p in tensor.named_parameters():\n",
    "        print(f\"Tensor: {name}.{n}, dtype: {p.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchao.quantization import quantize_\n",
    "from torchao.quantization import float8_weight_only\n",
    "# from torchao.quantization import float8_dynamic_activation_float8_weight\n",
    "import torch\n",
    "\n",
    "# torch.set_float32_matmul_precision(\"high\")\n",
    "# quantize_(flux_sampler.model, float8_weight_only())\n",
    "flux_sampler.model = flux_sampler.model.to(torch.float8_e4m3fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.quanto import freeze, qfloat8, quantize\n",
    "quantize(flux_sampler.model, weights=qfloat8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: img_in.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: img_in.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: time_in.in_layer.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: time_in.in_layer.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: time_in.out_layer.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: time_in.out_layer.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: vector_in.in_layer.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: vector_in.in_layer.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: vector_in.out_layer.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: vector_in.out_layer.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: guidance_in.in_layer.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: guidance_in.in_layer.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: guidance_in.out_layer.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: guidance_in.out_layer.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: txt_in.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: txt_in.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.0.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.1.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.2.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.3.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.4.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.5.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.6.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.7.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.8.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.9.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.10.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.11.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.12.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.13.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.14.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.15.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.16.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.17.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.img_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.img_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.img_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.img_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.img_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.img_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.img_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.img_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.img_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.img_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.txt_mod.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.txt_mod.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.txt_attn.qkv.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.txt_attn.qkv.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.txt_attn.proj.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.txt_attn.proj.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.txt_mlp.0.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.txt_mlp.0.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.txt_mlp.2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: double_blocks.18.txt_mlp.2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.0.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.0.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.0.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.0.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.0.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.0.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.1.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.1.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.1.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.1.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.1.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.1.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.2.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.2.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.2.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.2.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.2.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.2.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.3.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.3.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.3.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.3.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.3.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.3.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.4.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.4.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.4.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.4.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.4.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.4.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.5.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.5.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.5.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.5.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.5.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.5.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.6.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.6.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.6.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.6.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.6.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.6.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.7.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.7.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.7.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.7.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.7.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.7.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.8.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.8.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.8.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.8.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.8.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.8.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.9.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.9.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.9.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.9.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.9.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.9.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.10.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.10.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.10.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.10.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.10.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.10.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.11.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.11.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.11.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.11.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.11.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.11.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.12.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.12.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.12.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.12.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.12.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.12.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.13.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.13.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.13.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.13.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.13.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.13.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.14.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.14.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.14.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.14.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.14.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.14.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.15.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.15.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.15.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.15.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.15.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.15.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.16.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.16.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.16.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.16.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.16.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.16.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.17.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.17.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.17.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.17.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.17.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.17.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.18.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.18.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.18.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.18.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.18.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.18.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.19.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.19.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.19.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.19.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.19.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.19.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.20.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.20.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.20.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.20.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.20.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.20.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.21.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.21.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.21.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.21.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.21.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.21.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.22.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.22.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.22.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.22.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.22.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.22.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.23.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.23.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.23.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.23.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.23.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.23.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.24.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.24.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.24.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.24.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.24.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.24.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.25.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.25.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.25.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.25.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.25.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.25.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.26.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.26.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.26.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.26.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.26.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.26.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.27.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.27.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.27.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.27.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.27.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.27.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.28.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.28.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.28.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.28.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.28.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.28.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.29.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.29.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.29.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.29.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.29.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.29.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.30.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.30.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.30.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.30.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.30.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.30.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.31.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.31.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.31.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.31.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.31.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.31.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.32.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.32.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.32.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.32.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.32.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.32.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.33.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.33.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.33.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.33.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.33.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.33.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.34.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.34.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.34.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.34.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.34.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.34.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.35.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.35.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.35.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.35.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.35.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.35.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.36.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.36.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.36.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.36.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.36.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.36.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.37.linear1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.37.linear1.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.37.linear2.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.37.linear2.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.37.modulation.lin.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: single_blocks.37.modulation.lin.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: final_layer.linear.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: final_layer.linear.bias, dtype: torch.float8_e4m3fn\n",
      "Tensor: final_layer.adaLN_modulation.1.weight, dtype: torch.float8_e4m3fn\n",
      "Tensor: final_layer.adaLN_modulation.1.bias, dtype: torch.float8_e4m3fn\n"
     ]
    }
   ],
   "source": [
    "for name, tensor in flux_sampler.model.named_modules():\n",
    "    if hasattr(tensor, \"weight\"): # check if it's a layer, linear or conv, etc.\n",
    "       for n, p in tensor.named_parameters():\n",
    "        print(f\"Tensor: {name}.{n}, dtype: {p.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_block_linear_layer = flux_sampler.model.single_blocks[0].linear1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 21504)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_block_linear_layer.in_features, single_block_linear_layer.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(next(flux_sampler.model.single_blocks[0].parameters()).device)\n",
    "lora_path = \"fal_lora.safetensors\"\n",
    "flux_sampler.add_fal_lora(lora_path)\n",
    "# print(next(flux_sampler.model.single_blocks[0].parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9216, 1712])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(1712, 3072)\n",
    "b = torch.randn(3072, 3072)\n",
    "c = torch.randn(3072, 3072)\n",
    "d = torch.randn(3072, 3072)\n",
    "\n",
    "(torch.cat([b, c, d], dim=0) @ a.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/workspace/image-gen/.venv/lib/python3.10/site-packages/transformer_engine/pytorch/__init__.py:52\u001b[0m, in \u001b[0;36m_load_library\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     so_dir \u001b[38;5;241m=\u001b[39m get_te_path() \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformer_engine\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 52\u001b[0m     so_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mso_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodule_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.*.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mextension\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformer_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecipe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DelayedScaling\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformer_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FP8Module, fp8_autocast\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# flux_sampler.model = FP8Module(flux_sampler.model, DelayedScaling())\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/image-gen/.venv/lib/python3.10/site-packages/transformer_engine/pytorch/__init__.py:63\u001b[0m\n\u001b[1;32m     59\u001b[0m     sys\u001b[38;5;241m.\u001b[39mmodules[module_name] \u001b[38;5;241m=\u001b[39m solib\n\u001b[1;32m     60\u001b[0m     spec\u001b[38;5;241m.\u001b[39mloader\u001b[38;5;241m.\u001b[39mexec_module(solib)\n\u001b[0;32m---> 63\u001b[0m \u001b[43m_load_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformer_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayerNormLinear\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformer_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Linear\n",
      "File \u001b[0;32m~/workspace/image-gen/.venv/lib/python3.10/site-packages/transformer_engine/pytorch/__init__.py:55\u001b[0m, in \u001b[0;36m_load_library\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     so_dir \u001b[38;5;241m=\u001b[39m get_te_path()\n\u001b[0;32m---> 55\u001b[0m     so_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mso_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodule_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.*.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mextension\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m spec \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mspec_from_file_location(module_name, so_path)\n\u001b[1;32m     58\u001b[0m solib \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mmodule_from_spec(spec)\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformer_engine.common.recipe import DelayedScaling\n",
    "from transformer_engine.pytorch import FP8Module, fp8_autocast\n",
    "\n",
    "# flux_sampler.model = FP8Module(flux_sampler.model, DelayedScaling())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "flux_sampler.model = flux_sampler.model.to(torch.float8_e4m3fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating image with seed=0:\n",
      "prompt='Indian girl sitting in an auto'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"addmm_cuda\" not implemented for 'Float8_e4m3fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mflux_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIndian girl sitting in an auto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m480\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguidance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m img \n",
      "File \u001b[0;32m~/workspace/image-gen/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/image-gen/flux/pipeline.py:126\u001b[0m, in \u001b[0;36mFluxSampler.__call__\u001b[0;34m(self, prompt, width, height, seed, num_steps, guidance)\u001b[0m\n\u001b[1;32m    124\u001b[0m t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# denoise initial noise\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mdenoise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguidance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mguidance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39msynchronize()\n\u001b[1;32m    128\u001b[0m t3 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n",
      "File \u001b[0;32m~/workspace/image-gen/flux/sampling.py:261\u001b[0m, in \u001b[0;36mdenoise\u001b[0;34m(model, img, img_ids, txt, txt_ids, vec, timesteps, guidance, img_cond)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t_curr, t_prev \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(timesteps[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], timesteps[\u001b[38;5;241m1\u001b[39m:]):\n\u001b[1;32m    260\u001b[0m     t_vec \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],), t_curr, dtype\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 261\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_cond\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg_cond\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtxt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtxt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtxt_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtxt_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_vec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mguidance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mguidance_vec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     img \u001b[38;5;241m=\u001b[39m img \u001b[38;5;241m+\u001b[39m (t_prev \u001b[38;5;241m-\u001b[39m t_curr) \u001b[38;5;241m*\u001b[39m pred\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/workspace/image-gen/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/image-gen/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/workspace/image-gen/flux/model.py:99\u001b[0m, in \u001b[0;36mFlux.forward\u001b[0;34m(self, img, img_ids, txt, txt_ids, timesteps, y, guidance)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput img and txt tensors must have 3 dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# running on sequences img\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_in(timestep_embedding(timesteps, \u001b[38;5;241m256\u001b[39m))\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mguidance_embed:\n",
      "File \u001b[0;32m~/workspace/image-gen/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/image-gen/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/workspace/image-gen/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"addmm_cuda\" not implemented for 'Float8_e4m3fn'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "img = flux_sampler(prompt=\"Indian girl sitting in an auto\", width=480, height=640, seed=0, num_steps=50, guidance=3.5)\n",
    "img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float8_e4m3fn"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flux_sampler.model.txt_in.weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file as load_sft\n",
    "lora_path = \"fal_lora.safetensors\"\n",
    "lora_sd = load_sft(lora_path, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_key = next(k for k in lora_sd.keys() if 'lora_A.weight' in k)\n",
    "lora_rank = lora_sd[first_key].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.single_transformer_blocks.0.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.0.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.0.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.0.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.0.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.0.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.1.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.1.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.1.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.1.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.1.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.1.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.10.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.10.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.10.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.10.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.10.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.10.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.11.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.11.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.11.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.11.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.11.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.11.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.12.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.12.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.12.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.12.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.12.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.12.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.13.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.13.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.13.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.13.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.13.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.13.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.14.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.14.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.14.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.14.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.14.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.14.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.15.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.15.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.15.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.15.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.15.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.15.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.16.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.16.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.16.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.16.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.16.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.16.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.17.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.17.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.17.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.17.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.17.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.17.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.18.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.18.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.18.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.18.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.18.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.18.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.19.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.19.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.19.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.19.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.19.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.19.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.2.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.2.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.2.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.2.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.2.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.2.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.20.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.20.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.20.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.20.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.20.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.20.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.21.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.21.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.21.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.21.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.21.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.21.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.22.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.22.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.22.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.22.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.22.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.22.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.23.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.23.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.23.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.23.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.23.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.23.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.24.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.24.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.24.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.24.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.24.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.24.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.25.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.25.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.25.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.25.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.25.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.25.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.26.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.26.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.26.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.26.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.26.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.26.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.27.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.27.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.27.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.27.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.27.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.27.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.28.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.28.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.28.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.28.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.28.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.28.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.29.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.29.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.29.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.29.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.29.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.29.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.3.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.3.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.3.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.3.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.3.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.3.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.30.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.30.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.30.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.30.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.30.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.30.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.31.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.31.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.31.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.31.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.31.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.31.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.32.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.32.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.32.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.32.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.32.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.32.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.33.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.33.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.33.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.33.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.33.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.33.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.34.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.34.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.34.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.34.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.34.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.34.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.35.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.35.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.35.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.35.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.35.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.35.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.36.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.36.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.36.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.36.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.36.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.36.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.37.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.37.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.37.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.37.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.37.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.37.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.4.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.4.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.4.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.4.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.4.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.4.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.5.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.5.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.5.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.5.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.5.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.5.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.6.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.6.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.6.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.6.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.6.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.6.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.7.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.7.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.7.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.7.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.7.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.7.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.8.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.8.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.8.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.8.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.8.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.8.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.9.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.9.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.9.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.9.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.single_transformer_blocks.9.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.single_transformer_blocks.9.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.0.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.0.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.0.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.0.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.0.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.0.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.0.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.0.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.0.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.0.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.0.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.0.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.0.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.0.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.0.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.0.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.0.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.0.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.0.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.0.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.0.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.0.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.0.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.0.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.1.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.1.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.1.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.1.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.1.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.1.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.1.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.1.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.1.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.1.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.1.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.1.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.1.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.1.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.1.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.1.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.1.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.1.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.1.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.1.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.1.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.1.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.1.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.1.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.10.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.10.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.10.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.10.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.10.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.10.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.10.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.10.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.10.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.10.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.10.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.10.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.10.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.10.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.10.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.10.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.10.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.10.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.10.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.10.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.10.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.10.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.10.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.10.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.11.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.11.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.11.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.11.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.11.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.11.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.11.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.11.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.11.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.11.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.11.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.11.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.11.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.11.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.11.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.11.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.11.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.11.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.11.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.11.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.11.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.11.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.11.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.11.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.12.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.12.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.12.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.12.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.12.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.12.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.12.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.12.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.12.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.12.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.12.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.12.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.12.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.12.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.12.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.12.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.12.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.12.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.12.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.12.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.12.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.12.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.12.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.12.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.13.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.13.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.13.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.13.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.13.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.13.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.13.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.13.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.13.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.13.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.13.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.13.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.13.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.13.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.13.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.13.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.13.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.13.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.13.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.13.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.13.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.13.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.13.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.13.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.14.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.14.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.14.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.14.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.14.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.14.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.14.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.14.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.14.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.14.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.14.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.14.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.14.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.14.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.14.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.14.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.14.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.14.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.14.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.14.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.14.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.14.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.14.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.14.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.15.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.15.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.15.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.15.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.15.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.15.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.15.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.15.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.15.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.15.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.15.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.15.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.15.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.15.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.15.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.15.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.15.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.15.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.15.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.15.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.15.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.15.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.15.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.15.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.16.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.16.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.16.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.16.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.16.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.16.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.16.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.16.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.16.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.16.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.16.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.16.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.16.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.16.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.16.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.16.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.16.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.16.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.16.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.16.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.16.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.16.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.16.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.16.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.17.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.17.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.17.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.17.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.17.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.17.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.17.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.17.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.17.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.17.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.17.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.17.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.17.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.17.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.17.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.17.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.17.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.17.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.17.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.17.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.17.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.17.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.17.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.17.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.18.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.18.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.18.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.18.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.18.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.18.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.18.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.18.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.18.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.18.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.18.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.18.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.18.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.18.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.18.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.18.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.18.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.18.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.18.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.18.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.18.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.18.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.18.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.18.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.2.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.2.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.2.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.2.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.2.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.2.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.2.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.2.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.2.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.2.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.2.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.2.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.2.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.2.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.2.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.2.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.2.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.2.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.2.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.2.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.2.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.2.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.2.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.2.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.3.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.3.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.3.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.3.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.3.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.3.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.3.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.3.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.3.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.3.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.3.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.3.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.3.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.3.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.3.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.3.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.3.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.3.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.3.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.3.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.3.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.3.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.3.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.3.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.4.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.4.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.4.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.4.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.4.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.4.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.4.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.4.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.4.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.4.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.4.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.4.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.4.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.4.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.4.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.4.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.4.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.4.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.4.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.4.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.4.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.4.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.4.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.4.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.5.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.5.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.5.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.5.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.5.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.5.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.5.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.5.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.5.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.5.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.5.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.5.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.5.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.5.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.5.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.5.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.5.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.5.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.5.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.5.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.5.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.5.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.5.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.5.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.6.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.6.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.6.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.6.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.6.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.6.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.6.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.6.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.6.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.6.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.6.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.6.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.6.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.6.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.6.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.6.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.6.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.6.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.6.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.6.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.6.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.6.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.6.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.6.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.7.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.7.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.7.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.7.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.7.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.7.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.7.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.7.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.7.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.7.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.7.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.7.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.7.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.7.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.7.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.7.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.7.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.7.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.7.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.7.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.7.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.7.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.7.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.7.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.8.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.8.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.8.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.8.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.8.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.8.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.8.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.8.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.8.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.8.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.8.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.8.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.8.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.8.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.8.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.8.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.8.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.8.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.8.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.8.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.8.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.8.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.8.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.8.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.9.attn.add_k_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.9.attn.add_k_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.9.attn.add_q_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.9.attn.add_q_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.9.attn.add_v_proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.9.attn.add_v_proj.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.9.attn.to_add_out.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.9.attn.to_add_out.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.9.attn.to_k.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.9.attn.to_k.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.9.attn.to_out.0.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.9.attn.to_out.0.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.9.attn.to_q.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.9.attn.to_q.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.9.attn.to_v.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.9.attn.to_v.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.9.ff.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.9.ff.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.9.ff.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.9.ff.net.2.lora_B.weight:torch.Size([3072, 16])\n",
      "transformer.transformer_blocks.9.ff_context.net.0.proj.lora_A.weight:torch.Size([16, 3072])\n",
      "transformer.transformer_blocks.9.ff_context.net.0.proj.lora_B.weight:torch.Size([12288, 16])\n",
      "transformer.transformer_blocks.9.ff_context.net.2.lora_A.weight:torch.Size([16, 12288])\n",
      "transformer.transformer_blocks.9.ff_context.net.2.lora_B.weight:torch.Size([3072, 16])\n"
     ]
    }
   ],
   "source": [
    "for k, v in list(lora_sd.items()):\n",
    "    print(f\"{k}:{v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in list(lora_sd.items())[:10]:\n",
    "    print(f\"{k}:{v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flux.modules.lora import remap_lora_keys\n",
    "lora_remapped_sd = remap_lora_keys(lora_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_key = next(k for k in lora_remapped_sd.keys() if 'lora_A.weight' in k)\n",
    "lora_rank = lora_remapped_sd[first_key].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
